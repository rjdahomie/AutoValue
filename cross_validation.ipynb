{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IRY2DUkwwSGX"
   },
   "source": [
    "#Estimating the Test Error\n",
    "\n",
    "We learned about _training error_, which is the error calculated on the training data. Training error is easy to calculate because the true labels are available in the training data. However, training error is not always a good measure of a model's quality, since a model that _overfits_ to the training data may have artificially low training error.\n",
    "\n",
    "Ideally, we would like to evaluate regression models based on their _test error_, which is the error calculated on the test data. The problem with test error is that it is usually impossible to calculate, since the true labels are rarely available in the test data. In this section, we discuss strategies for estimating the test error using only the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q4lF5GaYwSGb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clean Alternative Fuel Vehicle Type</th>\n",
       "      <th>Model Year</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Vehicle Primary Use</th>\n",
       "      <th>Electric Range</th>\n",
       "      <th>Odometer Reading</th>\n",
       "      <th>New or Used Vehicle</th>\n",
       "      <th>Sale Price</th>\n",
       "      <th>Transaction Year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Car ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2014</td>\n",
       "      <td>MERCEDES-BENZ</td>\n",
       "      <td>B-Class</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>87</td>\n",
       "      <td>37031</td>\n",
       "      <td>Used</td>\n",
       "      <td>19443</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2018</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>Model 3</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>215</td>\n",
       "      <td>50</td>\n",
       "      <td>New</td>\n",
       "      <td>65700</td>\n",
       "      <td>2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2023</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>Model Y</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>New</td>\n",
       "      <td>84440</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2014</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>Model S</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>208</td>\n",
       "      <td>30840</td>\n",
       "      <td>Used</td>\n",
       "      <td>66864</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2022</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>Model Y</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>New</td>\n",
       "      <td>61440</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109424</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2022</td>\n",
       "      <td>RIVIAN</td>\n",
       "      <td>R1T</td>\n",
       "      <td>Truck</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>New</td>\n",
       "      <td>82295</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109425</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2022</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>Model 3</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>New</td>\n",
       "      <td>75290</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109426</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2011</td>\n",
       "      <td>NISSAN</td>\n",
       "      <td>Leaf</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>73</td>\n",
       "      <td>64000</td>\n",
       "      <td>Used</td>\n",
       "      <td>1540</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109427</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2020</td>\n",
       "      <td>TESLA</td>\n",
       "      <td>Model Y</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>291</td>\n",
       "      <td>24482</td>\n",
       "      <td>Used</td>\n",
       "      <td>68800</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109428</th>\n",
       "      <td>Battery Electric Vehicle (BEV)</td>\n",
       "      <td>2021</td>\n",
       "      <td>VOLKSWAGEN</td>\n",
       "      <td>ID.4</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>New</td>\n",
       "      <td>45690</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109428 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Clean Alternative Fuel Vehicle Type  Model Year           Make  \\\n",
       "Car ID                                                                  \n",
       "1           Battery Electric Vehicle (BEV)        2014  MERCEDES-BENZ   \n",
       "2           Battery Electric Vehicle (BEV)        2018          TESLA   \n",
       "3           Battery Electric Vehicle (BEV)        2023          TESLA   \n",
       "4           Battery Electric Vehicle (BEV)        2014          TESLA   \n",
       "5           Battery Electric Vehicle (BEV)        2022          TESLA   \n",
       "...                                    ...         ...            ...   \n",
       "109424      Battery Electric Vehicle (BEV)        2022         RIVIAN   \n",
       "109425      Battery Electric Vehicle (BEV)        2022          TESLA   \n",
       "109426      Battery Electric Vehicle (BEV)        2011         NISSAN   \n",
       "109427      Battery Electric Vehicle (BEV)        2020          TESLA   \n",
       "109428      Battery Electric Vehicle (BEV)        2021     VOLKSWAGEN   \n",
       "\n",
       "          Model Vehicle Primary Use  Electric Range  Odometer Reading  \\\n",
       "Car ID                                                                  \n",
       "1       B-Class           Passenger              87             37031   \n",
       "2       Model 3           Passenger             215                50   \n",
       "3       Model Y           Passenger               0                15   \n",
       "4       Model S           Passenger             208             30840   \n",
       "5       Model Y           Passenger               0                15   \n",
       "...         ...                 ...             ...               ...   \n",
       "109424      R1T               Truck               0               100   \n",
       "109425  Model 3           Passenger               0               187   \n",
       "109426     Leaf           Passenger              73             64000   \n",
       "109427  Model Y           Passenger             291             24482   \n",
       "109428     ID.4           Passenger               0                13   \n",
       "\n",
       "       New or Used Vehicle  Sale Price  Transaction Year  \n",
       "Car ID                                                    \n",
       "1                     Used       19443              2018  \n",
       "2                      New       65700              2018  \n",
       "3                      New       84440              2022  \n",
       "4                     Used       66864              2017  \n",
       "5                      New       61440              2022  \n",
       "...                    ...         ...               ...  \n",
       "109424                 New       82295              2022  \n",
       "109425                 New       75290              2022  \n",
       "109426                Used        1540              2022  \n",
       "109427                Used       68800              2022  \n",
       "109428                 New       45690              2022  \n",
       "\n",
       "[109428 rows x 10 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#Read the csv file\n",
    "cars_df = pd.read_csv(\"car.csv\")\n",
    "\n",
    "#Data cleaning: Remove unwanted columns\n",
    "cars_df = cars_df.iloc[:,[0,1,3,4,5,6,7,8,10,11,16]]\n",
    "\n",
    "#Data cleaning: Remove all rows with no sale price\n",
    "#Why not predict the price and not drop the row? \n",
    "#Because rows with no sale price are not guarenteed to have odometer reading\n",
    "#Additionaly, the dataset is big enough to be able to afford dropping rows\n",
    "cars_df = cars_df[cars_df[\"Sale Price\"] != 0]\n",
    "\n",
    "#Data cleaning: Remove all cars that are not Battery Electric Vehicle (Example: Hybrid cars)\n",
    "cars_df = cars_df[cars_df[\"Clean Alternative Fuel Vehicle Type\"] == \"Battery Electric Vehicle (BEV)\"]\n",
    "\n",
    "#Data cleaning: Getting rid of outliers\n",
    "cars_df = cars_df[cars_df[\"Odometer Reading\"] >= 0]\n",
    "cars_df = cars_df[cars_df[\"Odometer Reading\"] <= 250000]\n",
    "cars_df = cars_df[cars_df[\"Model Year\"] >= 2000]\n",
    "cars_df = cars_df[cars_df[\"Model Year\"] <= 2023]\n",
    "cars_df = cars_df[cars_df[\"Sale Price\"] <= 300000]\n",
    "cars_df = cars_df[cars_df[\"Sale Price\"] > 100]\n",
    "\n",
    "#Since we know each car has a unique vin number, we\n",
    "#can simplify the vin numbers and use them as index\n",
    "cars_df[\"VIN (1-10)\"] = cars_df.reset_index().index + 1\n",
    "cars_df = cars_df.rename(columns={\"VIN (1-10)\": \"Car ID\"})\n",
    "\n",
    "# Split the data into training and test sets.\n",
    "cars_df = cars_df.set_index(\"Car ID\")\n",
    "cars_train = cars_df.loc[:100000].copy()\n",
    "cars_test = cars_df.loc[100000:].copy()\n",
    "\n",
    "# Smaller sample data set which has chosen random rows (every 10th row)\n",
    "cars_temp = cars_df.iloc[::10, :]\n",
    "cars_temp = cars_temp.iloc[:,[1,2,3,6,7,8,9]]\n",
    "\n",
    "# Log transform the target(Sale Price) for visualization purposes only\n",
    "cars_train[\"log(Sale Price)\"] = np.log(cars_train[\"Sale Price\"])\n",
    "\n",
    "cars_df\n",
    "#cars_train\n",
    "#cars_test\n",
    "#cars_temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFJ697u6wSGh"
   },
   "source": [
    "## Validation Error\n",
    "\n",
    "To estimate the test error, we split the training data into a _training set_ and a _validation set_. First, the model is fit to just the data in the training set. Then, the model is evaluated based on its predictions on the validation set. Because the model did not train on any of the labels in the validation set, the validation set essentially plays the role of the test data, even though it was carved out of the training data.\n",
    "\n",
    "The prediction error on the validation set is known as the _validation error_. The validation error is an approximation to the test error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TM0_UeM0wSGi"
   },
   "source": [
    "To split our data into training and validation sets, we can use the `.sample()` function in `pandas`. Let's use this to split our data into two equal halves, which we will call `train` and `val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "knhAhaUFwSGj"
   },
   "outputs": [],
   "source": [
    "train = cars_temp.sample(frac=.5)\n",
    "val = cars_temp.drop(train.index)\n",
    "\n",
    "#train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UnBEofgcwSGr"
   },
   "source": [
    "Now let's use these training/validation sets to approximate the test MSE of the 5-nearest neighbors model that we fit in Chapter 5.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "27lsWT1jwSGs"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('minmaxscaler',\n",
       "                                                  MinMaxScaler(),\n",
       "                                                  ['Model Year',\n",
       "                                                   'Odometer Reading']),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
       "                                                  ['Make', 'Model'])])),\n",
       "                ('kneighborsregressor', KNeighborsRegressor(n_neighbors=10))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (MinMaxScaler(), [\"Model Year\", \"Odometer Reading\"]),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), [\"Make\", \"Model\"]),\n",
    "    remainder=\"drop\"  # all other columns in X will be dropped.\n",
    ")\n",
    "\n",
    "pipeline = make_pipeline(\n",
    "    ct,\n",
    "    KNeighborsRegressor(n_neighbors=10)\n",
    ")\n",
    "\n",
    "pipeline.fit(X=cars_df[[\"Model Year\", \"Odometer Reading\", \"Make\", \"Model\"]], \n",
    "             y=cars_df[\"Sale Price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XGyACJ3owSGy"
   },
   "source": [
    "We make predictions on the validation set and calculate the validation RMSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FxOBTtpGwSG0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8671.874954144356"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# extract features and label from validation set\n",
    "X_val = val[[\"Model Year\", \"Odometer Reading\", \"Make\", \"Model\"]]\n",
    "y_val = val[\"Sale Price\"]\n",
    "\n",
    "# get model's predictions on validation set\n",
    "y_val_ = pipeline.predict(X_val)\n",
    "\n",
    "# calculate RMSE on validation set\n",
    "rmse = np.sqrt(mean_squared_error(y_val, y_val_))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ciJmVtvZwSG4"
   },
   "source": [
    "Notice that the test error is higher than the training error that we calculated in the previous lesson. In general, this will be true. It is harder for a model to predict for new observations it has not seen, than for observations it has seen!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t2JE820swSG6"
   },
   "source": [
    "## Cross Validation\n",
    "\n",
    "The validation error above was calculated using only 50% of the training data, since we split the training data in half to create the validation set. As a result, the estimate is noisy.\n",
    "\n",
    "There is a cheap way to obtain a second opinion about how well our model will do on future data. Previously, we split our data at random into two halves, fitting the model to the first half and evaluating it on the second half. Because the model has not already seen the second half of the data, this approximates how well the model would perform on future data. \n",
    "\n",
    "But the way we split our data was arbitrary. We might as well swap the roles of the two halves, fitting the model to the _second_ half and evaluating it on the _first_ half. As long as the model is always evaluated on data that is different from the data that was used to train it, we have a valid estimate of test error. A schematic of this approach, known as _cross-validation_, is shown below.\n",
    "\n",
    "![](https://github.com/dlsun/pods/blob/master/05-Regression-Models/cross-validation.png?raw=1)\n",
    "\n",
    "Because we will be doing all computations twice, just with different data, let's wrap the $k$-nearest neighbors algorithm above into a function called `get_val_error()`, that computes the validation error given training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gh5vfQLmwSG6"
   },
   "outputs": [],
   "source": [
    "def get_val_error(train, val):\n",
    "    \n",
    "    ct = make_column_transformer(\n",
    "        (MinMaxScaler(), [\"Model Year\", \"Odometer Reading\"]),\n",
    "        (OneHotEncoder(handle_unknown='ignore'), [\"Make\", \"Model\"]),\n",
    "        remainder=\"drop\"  # all other columns in X will be dropped.\n",
    "    )\n",
    "\n",
    "    pipeline = make_pipeline(\n",
    "        ct,\n",
    "        KNeighborsRegressor(n_neighbors=7)\n",
    "    )\n",
    "    \n",
    "    pipeline.fit(X=cars_temp[[\"Model Year\", \"Odometer Reading\", \"Make\", \"Model\"]], \n",
    "             y=cars_temp[\"Sale Price\"])\n",
    "    \n",
    "    # extract features and label from validation set\n",
    "    X_val = val[[\"Model Year\", \"Odometer Reading\", \"Make\", \"Model\"]]\n",
    "    y_val = val[\"Sale Price\"]\n",
    "    \n",
    "    # get model's predictions on validation set\n",
    "    y_val_ = pipeline.predict(X_val)\n",
    "\n",
    "    # calculate RMSE on validation set\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_val_))\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJiEMg2YwSG9"
   },
   "source": [
    "If we apply this function to the training and validation sets from earlier, we get the same estimate of the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0S5FaE45wSG-"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8618.60474088509"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_error(train, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbHcEHYRwSHA"
   },
   "source": [
    "But if we reverse the roles of the training and validation sets, we get another estimate of the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k21Av7jAwSHC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8915.055575818576"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_val_error(val, train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y1ZVZ2i-wSHG"
   },
   "source": [
    "Now we have two, somewhat independent estimates of the test error. It is common to average the two numbers to obtain an overall estimate of the test error, called the _cross-validation estimate of test error_. Notice that the cross-validation estimate uses each observation in the data exactly once. We make a prediction for each observation, but always using a model that was trained on data that does not include that observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jIjOMuqcwSHH"
   },
   "source": [
    "## Cross-Validation in scikit-learn\n",
    "\n",
    "As you know by now, scikit-learn provides functions that automate routine tasks of machine learning. For cross-validation, there is a function, `cross_val_score`, that takes in a model (or pipeline), the training data, and a scoring function, and carries out all aspects of cross-validation, including\n",
    "\n",
    "1. splitting the training data into training and validation sets\n",
    "2. fitting the model to each training set\n",
    "3. calculating the model's predictions on the corresponding validation set\n",
    "4. calculating the score of the predictions on each validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hYSufCjlwSHI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(pipeline, \n",
    "                         X=cars_df[[\"Model Year\", \"Odometer Reading\", \"Make\", \"Model\"]],\n",
    "                         y=cars_df[\"Sale Price\"],\n",
    "                         scoring=\"neg_mean_squared_error\",\n",
    "                         cv=10)\n",
    "#scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SgiIBYoswSHM"
   },
   "source": [
    "First, notice that there are 2 scores. This is because scikit-learn calculated a score from each half of the data when that half served as the validation set.\n",
    "\n",
    "Second, observe that the scores are negative. This is because scikit-learn requires that a \"score\" be something that ought to be maximized. Since we want to minimize the mean-squared error, we want to maximize the *negative* mean-squared error. Therefore, the scores that are reported here are the negative of the MSE.\n",
    "\n",
    "To calculate the RMSE, we negate the negative sign and take a square root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cYNXVJGAwSHN"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8906.72824935, 10210.52099906,  9443.69691343,  9179.9544375 ,\n",
       "        9279.69911128,  9451.1871284 ,  9007.50765644,  9047.2061077 ,\n",
       "       10319.94516668,  8983.72589418])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MAI8ViZcwSHR"
   },
   "source": [
    "The average of these two scores is the cross-validation estimate of test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z7YLXSOcwSHS"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9383.01716640086"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-scores).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rKsW_3PiwSHV"
   },
   "source": [
    "## $K$-Fold Cross Validation\n",
    "\n",
    "One problem with splitting the training data into two halves is that the model is now trained on only half the amount of data. This model will likely perform worse than the actual model, which is trained on all of the training data. So the cross-validation estimate of test error is unnecessarily pessimistic.\n",
    "\n",
    "We would like the size of the training set to be closer to the size of the original training data. We can do this by splitting the data into more than two subsamples. In general, we can split the data into $k$ subsamples, alternately training the data on $k-1$ subsamples and evaluating the model on the $1$ remaining subsample, i.e., the validation set. This produces $k$ somewhat independent estimates of the test error. This procedure is known as **$k$-fold cross validation**. (Be careful not to confuse this $k$ with the $k$ in $k$-nearest neighbors.) In hindsight, the  cross validation that we were doing previously is $2$-fold cross validation.\n",
    "\n",
    "A schematic of $4$-fold cross validation is shown below.\n",
    "\n",
    "![](https://github.com/dlsun/pods/blob/master/05-Regression-Models/k-folds.png?raw=1)\n",
    "\n",
    "Implementing $k$-fold cross validation in scikit-learn is easy. We simply set the `cv=` parameter to the desired number of folds. For example, the following code carries out $4$-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ooh9RLfRwSHW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.55190095e+07, -9.15928569e+07, -9.14499008e+07, -1.04208179e+08])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(pipeline, \n",
    "                         X=cars_temp[[\"Model Year\", \"Odometer Reading\", \"Make\", \"Model\",\"New or Used Vehicle\", \"Transaction Year\"]],\n",
    "                         y=cars_temp[\"Sale Price\"],\n",
    "                         scoring=\"neg_mean_squared_error\",\n",
    "                         cv=4)\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CaNyndUkwSHZ"
   },
   "source": [
    "Notice that $k$ scores are produced, one from each fold. These scores can be averaged to produce a single estimate of the test error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNBeVkV_wSHZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9778.745830533117"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(-scores).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "5.5 Estimating the Test Error.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
